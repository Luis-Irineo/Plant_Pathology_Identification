{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68f7c52a-4592-4dbe-b719-da317e8386cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Import libraries\n",
    "# Warnings configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# General Libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Neural Network Components\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "warnings.filterwarnings('always')\n",
    "\n",
    "#%% WANDB function creation\n",
    "def wandb_block(params, sampling_interval, project, group):\n",
    "    config_directory = params\n",
    "    trial_number = config_directory[\"name\"]\n",
    "    run = wandb.init(\n",
    "        settings=wandb.Settings(x_disable_stats=False, x_stats_sampling_interval = sampling_interval),\n",
    "        # set the wandb project where this run will be logged\n",
    "        name = f\"Trial_{trial_number}\",\n",
    "        project = project,\n",
    "        group = group,\n",
    "        # track hyperparameters and run metadata with wandb.config\n",
    "        config = config_directory\n",
    "    )\n",
    "    time.sleep(3.0)\n",
    "    return run\n",
    "      \n",
    "#%% Neural Network Constructor\n",
    "class NeuralNetworkConstructor:\n",
    "    def __init__(self, inputs, filters=64, total_categories=2, conv_blocks=2, maxpooling_rate=2, bottleneck_length=2, \n",
    "                 downwards_activations=[None]*4, downwards_dropouts=[0.2,0.2], downwards_regularizers=[None]*4,\n",
    "                 bottleneck_activations=[None]*2, bottleneck_dropout=0.2, bottleneck_regularizers=[None]*2,\n",
    "                 upwards_activations=[None]*4, upwards_dropouts=[0.2,0.2], upwards_regularizers=[None]*4,\n",
    "                 classifier_activation=\"relu\"):\n",
    "        self.inputs = inputs\n",
    "        self.conv_blocks = conv_blocks\n",
    "        self.maxpooling_rate = maxpooling_rate\n",
    "        self.bottleneck_length = bottleneck_length\n",
    "        self.filters =  filters\n",
    "        self.complete_length = conv_blocks*maxpooling_rate\n",
    "        self.residuals = [None]*conv_blocks\n",
    "        self.total_categories = total_categories\n",
    "        self.downwards_activations = downwards_activations\n",
    "        self.downwards_dropouts = downwards_dropouts \n",
    "        self.downwards_regularizers = downwards_regularizers \n",
    "        \n",
    "        self.bottleneck_activations = bottleneck_activations \n",
    "        self.bottleneck_dropout = bottleneck_dropout \n",
    "        self.bottleneck_regularizers = bottleneck_regularizers \n",
    "        \n",
    "        self.upwards_activations = upwards_activations \n",
    "        self.upwards_dropouts = upwards_dropouts  \n",
    "        self.upwards_regularizers = upwards_regularizers\n",
    "        self.classifier_activation = classifier_activation\n",
    "    \n",
    "    def selected_regularizer(self, regularizer):\n",
    "        if regularizer is None:\n",
    "            selected_regularizer = \"None\"\n",
    "        elif regularizer == \"L1L2\":\n",
    "            selected_regularizer = f\"keras.regularizers.{regularizer}(l1 = 1e-5, l2 = 1e-5)\"\n",
    "        else:\n",
    "            selected_regularizer = f\"keras.regularizers.{regularizer}(1e-5)\"\n",
    "        return selected_regularizer\n",
    "        \n",
    "    \n",
    "    def downwards_path_iterator(self, block_inputs):\n",
    "        x = block_inputs\n",
    "        count=0\n",
    "        for i in range(self.complete_length):\n",
    "            current_filter = self.filters*(i//self.maxpooling_rate+1)\n",
    "            current_activation = self.downwards_activations[i]\n",
    "            current_regularizer = self.selected_regularizer(\n",
    "                self.downwards_regularizers[i]\n",
    "            )\n",
    "            x = layers.Conv2D(filters=current_filter,\n",
    "                              kernel_size=(3,3),\n",
    "                              padding='valid',\n",
    "                              activation=current_activation,\n",
    "                              kernel_regularizer=eval(current_regularizer),\n",
    "                              name=f'DownConv{i+1}')(x)\n",
    "            x = layers.BatchNormalization(name=f'DownBN{i+1}')(x)\n",
    "            \n",
    "            if (i+1)%self.maxpooling_rate==0:\n",
    "                self.residuals[count]=x\n",
    "                x=layers.MaxPooling2D((2,2), padding='same',\n",
    "                                      name=f'MaxPool{count+1}')(x)\n",
    "                x=layers.Dropout(self.downwards_dropouts[count],\n",
    "                                 name=f'DownDO{count+1}')(x)\n",
    "                count+=1\n",
    "                \n",
    "        downwards_output = x\n",
    "        return downwards_output\n",
    "    \n",
    "    def bottleneck_path_iterator(self, block_inputs):\n",
    "        current_filter = self.filters*self.conv_blocks*2\n",
    "        x = block_inputs\n",
    "        for i in range(self.bottleneck_length):\n",
    "            current_activation = self.bottleneck_activations[i]\n",
    "            current_regularizer = self.selected_regularizer(\n",
    "                self.bottleneck_regularizers[i]\n",
    "            ) \n",
    "            x = layers.Conv2D(filters=current_filter,\n",
    "                              kernel_size=(3,3),\n",
    "                              padding='valid',\n",
    "                              activation=current_activation,\n",
    "                              kernel_regularizer=eval(current_regularizer),\n",
    "                              name=f'BotConv{i+1}')(x)\n",
    "            x = layers.BatchNormalization(name=f'BotBN{i+1}')(x)\n",
    "        x = layers.Dropout(self.bottleneck_dropout,\n",
    "                           name=\"BN_Dropout\")(x)\n",
    "        bottleneck_output = x\n",
    "        return bottleneck_output\n",
    "\n",
    "    def upwards_path_iterator(self, block_inputs):\n",
    "        current_filter = self.filters*self.conv_blocks*2\n",
    "        count = 0\n",
    "        x = block_inputs\n",
    "        for i in range(self.complete_length):\n",
    "            current_activation = self.upwards_activations[i]\n",
    "            current_regularizer = self.selected_regularizer(\n",
    "                self.upwards_regularizers[i]\n",
    "            )\n",
    "            if i%self.maxpooling_rate==0:\n",
    "                count+=1\n",
    "                residual = self.residuals[self.conv_blocks-count]\n",
    "                x = layers.Conv2DTranspose(filters=current_filter,\n",
    "                                           kernel_size=(2,2),\n",
    "                                           strides=(2,2),\n",
    "                                           padding='same',\n",
    "                                           name=f'UpSamp{i//self.maxpooling_rate+1}')(x)\n",
    "                r_shape=residual.shape\n",
    "                x_shape=x.shape\n",
    "                #rescalamos el residual\n",
    "                residual=layers.Resizing(x_shape[1], \n",
    "                                         x_shape[2],\n",
    "                                         interpolation=\"bilinear\")(residual)\n",
    "                # unimos los residuals con las activaciones actuales\n",
    "                x = layers.Concatenate(axis=-1)([x, residual])\n",
    "                x=layers.Dropout(self.downwards_dropouts[count-1],\n",
    "                                 name=f'UpDO{count}')(x)\n",
    "                current_filter= current_filter//2\n",
    "                \n",
    "            x = layers.Conv2D(filters=current_filter,\n",
    "                              kernel_size=(3,3),\n",
    "                              padding='valid',\n",
    "                              activation=current_activation,\n",
    "                              kernel_regularizer=eval(current_regularizer),\n",
    "                              name=f'UpConv{i+1}')(x)\n",
    "            \n",
    "            x = layers.BatchNormalization(name=f'UpBN{i+1}')(x)\n",
    "        upwards_output = x\n",
    "        return upwards_output\n",
    "\n",
    "    def complete_outputs(self):\n",
    "        x=self.inputs\n",
    "        x=self.downwards_path_iterator(x)\n",
    "        x=self.bottleneck_path_iterator(x)\n",
    "        x=self.upwards_path_iterator(x)\n",
    "        x=layers.Conv2D(filters=self.total_categories,\n",
    "                        kernel_size=(1,1),\n",
    "                        padding='valid',\n",
    "                        activation=self.classifier_activation,\n",
    "                        name='segmentation_map')(x)\n",
    "        outputs=x\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "398f40bc-68c6-4c21-8a80-2641708a5615",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m inputs=keras.Input((\u001b[32m2048\u001b[39m,\u001b[32m1365\u001b[39m,\u001b[32m3\u001b[39m))\n\u001b[32m      2\u001b[39m creator = NeuralNetworkConstructor(inputs=inputs)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m outputs = \u001b[43mcreator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomplete_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m model = keras.Model(inputs=inputs,outputs=outputs)\n\u001b[32m      5\u001b[39m model.summary()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 166\u001b[39m, in \u001b[36mNeuralNetworkConstructor.complete_outputs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcomplete_outputs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    165\u001b[39m     x=\u001b[38;5;28mself\u001b[39m.inputs\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     x=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownwards_path_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m     x=\u001b[38;5;28mself\u001b[39m.bottleneck_path_iterator(x)\n\u001b[32m    168\u001b[39m     x=\u001b[38;5;28mself\u001b[39m.upwards_path_iterator(x)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 81\u001b[39m, in \u001b[36mNeuralNetworkConstructor.downwards_path_iterator\u001b[39m\u001b[34m(self, block_inputs)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.complete_length):\n\u001b[32m     80\u001b[39m     current_filter = \u001b[38;5;28mself\u001b[39m.filters*(i//\u001b[38;5;28mself\u001b[39m.maxpooling_rate+\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     current_activation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownwards_activations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     82\u001b[39m     current_regularizer = \u001b[38;5;28mself\u001b[39m.selected_regularizer(\n\u001b[32m     83\u001b[39m         \u001b[38;5;28mself\u001b[39m.downwards_regularizers[i]\n\u001b[32m     84\u001b[39m     )\n\u001b[32m     85\u001b[39m     x = layers.Conv2D(filters=current_filter,\n\u001b[32m     86\u001b[39m                       kernel_size=(\u001b[32m3\u001b[39m,\u001b[32m3\u001b[39m),\n\u001b[32m     87\u001b[39m                       padding=\u001b[33m'\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     88\u001b[39m                       activation=current_activation,\n\u001b[32m     89\u001b[39m                       kernel_regularizer=\u001b[38;5;28meval\u001b[39m(current_regularizer),\n\u001b[32m     90\u001b[39m                       name=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mDownConv\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)(x)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "inputs=keras.Input((2048,1365,3))\n",
    "creator = NeuralNetworkConstructor(inputs=inputs)\n",
    "outputs = creator.complete_outputs()\n",
    "model = keras.Model(inputs=inputs,outputs=outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b57e43-c953-452a-8080-4c060342a4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
