{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e055ce-b34b-4b64-a642-7078e9a07149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 02:01:03.988267: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-01 02:01:04.135545: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-01 02:01:06.045236: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "#%% Import libraries\n",
    "# Warnings configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# General Libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Neural Network Components\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb86b712-2a96-49f9-886f-5542ce2a6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"/tf/Tarea_6\") \n",
    "from ANN_creator_module import NeuralNetworkConstructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7a1e2d6-773f-437c-9c4b-610893a396b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_block(params):\n",
    "    config_directory = params\n",
    "    trial_number = config_directory[\"name\"]\n",
    "    \n",
    "    run = wandb.init(\n",
    "        settings=wandb.Settings(x_disable_stats=False, x_stats_sampling_interval = sampling_interval),\n",
    "        # set the wandb project where this run will be logged\n",
    "        name = f\"Trial_{trial_number}\",\n",
    "        project = config_directory['project'],\n",
    "        group = config_directory['project'],\n",
    "        # track hyperparameters and run metadata with wandb.config\n",
    "        config = config_director\n",
    "    )\n",
    "    time.sleep(3.0)\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62673fe2-274d-4b04-86d5-7134b5b93162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder:\n",
    "    def __init__(self, trial, inputs, total_classes):\n",
    "        # INITIAL CONFIGURATION\n",
    "        self.project = 'Plant_Pathology_Classifier'\n",
    "        self.group = 'Mini_Train'\n",
    "        self.loss = 'categorical_crossentropy'\n",
    "        self.metrics = 'val_loss'\n",
    "        self.batch_size = 25\n",
    "        self.sampling_interval = 20\n",
    "        self.inputs=inputs\n",
    "        self.total_classes = total_classes\n",
    "        \n",
    "        # PRIMARY OPTUNA SUGGESTIONS\n",
    "        self.trial_number = trial\n",
    "        self.conv_blocks = trial.suggest_int('conv_blocks', 1, 5)\n",
    "        self.maxpooling_rate = trial.suggest_int('maxpooling_tate', 1, 5)\n",
    "        self.bottleneck_length = trial.suggest_int('conv_blocks', 1, 5)\n",
    "        self.total_\n",
    "        self.filters = trial.suggest_int('conv_blocks', 16, 256, step=16)\n",
    "        self.complete_length = self.conv_blocks*self.maxpooling_rate\n",
    "        self.bottleneck_dropout = trial.suggest_float('bottleneck_dropout', 0.1, 0.5)\n",
    "        self.optimizer = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\", \"RMSprop\", \"Nadam\"])\n",
    "        self.classifier_activation = 'softmax'\n",
    "        \n",
    "        # INITIALIZING THE CODER LISTS\n",
    "        self.downwards_activations = [None]*self.complete_length\n",
    "        self.downwards_dropouts = [None]*self.maxpooling_rate\n",
    "        self.downwards_regularizers = [None]*self.complete_length\n",
    "        \n",
    "        # INITIALIZING THE BOTTLENECK LISTS\n",
    "        self.bottleneck_activations = [None]*self.bottleneck_length\n",
    "        self.bottleneck_regularizers = [None]*self.bottleneck_length\n",
    "        \n",
    "        # INITIALIZING THE DECODER LISTS\n",
    "        self.upwards_activations = [None]*self.complete_length\n",
    "        self.upwards_dropouts = [None]*self.maxpooling_rate \n",
    "        self.upwards_regularizers = [None]*self.complete_length\n",
    "        \n",
    "        \n",
    "        \n",
    "        # SECONDARY OPTUNA SUGGESTIONS\n",
    "        for i in range(self.bottleneck_length):\n",
    "            activation_name = trial.suggest_categorical(f'BN_activation{i}', \n",
    "                                                        ['relu','tanh','leaky_relu','elu','silu','mish'])\n",
    "            regularizer_name = trial.suggest_categorical(f'BN_regularizer{i}',\n",
    "                                                        [None, 'L1L2', \"L1\", \"L2\"])\n",
    "            self.bottleneck_activations[i] = activation_name\n",
    "            self.bottleneck_regularizers[i] = regularizer_name\n",
    "        \n",
    "        for i in range(self.total_length):\n",
    "            activation_name = trial.suggest_categorical(f'DW_activation{i}', \n",
    "                                                        ['relu','tanh','leaky_relu','elu','silu','mish'])\n",
    "            dropout_value = trial.suggest_float(f'DW_dropout{i}',0.1,0.5)\n",
    "            regularizer_name = trial.suggest_categorical(f'DW_regularizer{i}',\n",
    "                                                        [None, 'L1L2', \"L1\", \"L2\"])\n",
    "            self.downwards_activations[i] = activation_name\n",
    "            self.downwards_dropouts[i] = dropout_value\n",
    "            self.downwards_regularizers[i] = regularizer_name\n",
    "\n",
    "        for i in range(self.total_length):\n",
    "            activation_name = trial.suggest_categorical(f'UW_activation{i}', \n",
    "                                                        ['relu','tanh','leaky_relu','elu','silu','mish'])\n",
    "            dropout_value = trial.suggest_float(f'UW_dropout{i}',0.1,0.5)\n",
    "            regularizer_name = trial.suggest_categorical(f'UW_regularizer{i}',\n",
    "                                                        [None, 'L1L2', \"L1\", \"L2\"])\n",
    "            self.upwards_activations[i] = activation_name\n",
    "            self.upwards_dropouts[i] = dropout_value\n",
    "            self.upwards_regularizers[i] = regularizer_name\n",
    "        \n",
    "        self.model = self._build_model()\n",
    "    \n",
    "    def get_params(self, params_type=1):\n",
    "        wandb_params = {\n",
    "            'name': self.trial_number,\n",
    "            'project': self.project,\n",
    "            'group': self.group,\n",
    "            'optimizer': self.optimizer,\n",
    "            'loss': self.loss,\n",
    "            'batch_size': self.batch_size,\n",
    "            'filters': self.filters,\n",
    "        }\n",
    "        ann_params = {\n",
    "            'filters': self.filters,\n",
    "            'conv_blocks': self.conv_blocks, \n",
    "            'maxpooling_rate': self.maxpooling_rate,\n",
    "            'bottleneck_lenght': self.bottleneck_lenght,\n",
    "            'downwards_activations': self.downwards_activations,\n",
    "            'downwards_dropouts': self.downwards_dropouts,\n",
    "            'downwards_regularizers': self.downwards_regularizers,\n",
    "            'bottleneck_activations': self.bottleneck_activations,\n",
    "            'bottleneck_dropout': self.bottleneck_dropout,\n",
    "            'bottleneck_regularizers': self.bottleneck_regularizers,\n",
    "            'upwards_activations':self.upwards_activations,\n",
    "            'upwards_regularizers':self.upwards_regularizers,\n",
    "            'upwards_dropouts':self.upwards_dropouts,\n",
    "            'classifier_activation': self.classifier_activation,\n",
    "        }\n",
    "        if params_type==0:\n",
    "            params = wandb_params\n",
    "        elif params_type==1: \n",
    "            params = ann_params\n",
    "        elif params_type==2:\n",
    "            params = wand_params | ann_params\n",
    "        else:\n",
    "            warnings.warn(\"params_type must be 0 (for wandb parameters), 1 (for ann parameters) or 2 (for all parameters)\", \n",
    "                          UserWarning)\n",
    "            params = None\n",
    "        return params\n",
    "        \n",
    "    def _build_model(self):\n",
    "        inputs = self.inputs\n",
    "        total_categories = self.total_categories\n",
    "        params = self.get_params(1)\n",
    "        Neural_network_constructor = NeuralNetworkConstructor(inputs, total_categories, **params)\n",
    "        outputs = NeuralNetworkConstructor.complete_outputs()\n",
    "        model = keras.Model(inputs=inputs,\n",
    "                            outputs=outputs)\n",
    "        model.compile(optimizer=self.optimizer,\n",
    "                     loss=self.loss,\n",
    "                     metrics=[self.metrics])\n",
    "        return model\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96551d24-b4bb-48f5-99fc-60adbfe06ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor ='val_loss',\n",
    "        min_delta = 0.001,\n",
    "        patience = 50, \n",
    "        restore_best_weights = True,\n",
    "        mode = \"auto\",\n",
    "        verbose = 1,\n",
    "        baseline = None)\n",
    "    \n",
    "    builder = ModelBuilder(trial, inputs=keras.Inputs((2048,1365,3)),\n",
    "                          total_classes=6)\n",
    "    \n",
    "    model = builder.get_model()\n",
    "    params = builder.get_params(2)\n",
    "    run = wandb_block(**params)\n",
    "    \n",
    "    model.fit(X_train, y_train, \n",
    "              epochs = builder.epoch, \n",
    "              batch_size = builder.batch_size, \n",
    "              verbose = 0,\n",
    "              validation_data = (X_test, y_test),\n",
    "              callbacks = [\n",
    "                  WandbMetricsLogger(log_freq = builder.sampling_interval),\n",
    "                  #WandbModelCheckpoint(\"models/model.keras\"),\n",
    "                  early_stopping\n",
    "              ]\n",
    "             )\n",
    "    run.finish()\n",
    "    trial_number = params[\"name\"]\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose = 0)\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
